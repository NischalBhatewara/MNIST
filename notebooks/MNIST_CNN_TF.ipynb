{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CNN to predict MNIST images using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building TF graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an input node, shape is 28*28 for the number of pixels and None for batch_size(as in variable batch size)\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28*28], name='x')\n",
    "\n",
    "# we reshape x to a 4d tensor of size [-1, 28, 28, 1], 28 for image height and width, 1 for channel\n",
    "x_train = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# the expected output \n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10], name='y_')\n",
    "y_cls = tf.arg_max(y_, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first conv layer uses 32 filters of shape 5x5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init weights and bias\n",
    "\n",
    "# here we get truncated_normal values with a std deviation of 0.1\n",
    "# the shape is - [5, 5, 1, 16] for 5x5 filter, 1 input channel (as mnist is grey-scale), and 16 output channels\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 16], stddev=0.1))\n",
    "\n",
    "# bias for each of the 16 output channels\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a conv layer\n",
    "# input is x_train, specifies the input to the layer\n",
    "# filers are the weights \n",
    "# stride is [1, 1, 1, 1], the first and last are always 1, first for image number and the last for input channel\n",
    "# for a 2x2 stride, use [1, 2, 2, 1]\n",
    "# padding = same, the input image is padded with 0, to make output of same size\n",
    "conv1 = tf.nn.conv2d(input=x_train, filter=W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# add the bias \n",
    "conv1_plus_b = conv1 + b_conv1\n",
    "\n",
    "# max pool this layer\n",
    "# the value is the layer to pool upon\n",
    "# ksize?\n",
    "pool1 = tf.nn.max_pool(value=conv1_plus_b, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# apply relu\n",
    "# basically computers max(x, 0) for each x\n",
    "relu1 = tf.nn.relu(pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_5:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above, build second conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weight and bias\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 16, 32], stddev=0.1))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "# build layer\n",
    "conv2 = tf.nn.conv2d(input=relu1, filter=W_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2_plus_b = conv2 + b_conv2\n",
    "pool2 = tf.nn.max_pool(value=conv2_plus_b, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "relu2 = tf.nn.relu(pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_6:0' shape=(?, 7, 7, 32) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conv layer 2 outputs a 4d tensor, but we need a 2d tensor for the fully connected layer, thus this flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_layer = tf.reshape(relu2, [-1, 7 * 7 * 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_10:0' shape=(?, 1568) dtype=float32>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first fully connected layer, with 128 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weight and bias\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([7 * 7 * 32, 128], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "\n",
    "# fc layer\n",
    "math_fc1 = tf.matmul(flat_layer, W_fc1) + b_fc1\n",
    "fc1 = tf.nn.relu(math_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_7:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer randomly drops a few neurons, to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "drop_out = tf.nn.dropout(fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_1/mul:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrond FC layer, has 10 neurons, each for one of the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight and bias\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([128 ,10], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "\n",
    "# fc layer\n",
    "fc2 = tf.matmul(drop_out, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_11:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a softmax layer to normalize the output, and use argmax to get digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(fc2)\n",
    "y_pred_cls = tf.arg_max(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax_3:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have finished building out CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost (to minimize)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=fc2, labels=y_)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# using adamoptimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "# pref measures\n",
    "correct_pred = tf.equal(y_pred_cls, y_cls)\n",
    "acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper to optimize\n",
    "tot_iter = 0\n",
    "\n",
    "def optimize(num_iter):\n",
    "    global tot_iter\n",
    "    \n",
    "    for i in range(tot_iter, tot_iter + num_iter):\n",
    "        \n",
    "        x_batch, y_batch = data.train.next_batch(batch_size)\n",
    "        f_d = {x: x_batch, y_: y_batch, keep_prob: 0.5}\n",
    "        \n",
    "        session.run(optimizer, feed_dict=f_d)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            a = session.run(acc, f_d)\n",
    "            msg = \"Iteration: {0:>6}, Acc: {1:6.1%}\"\n",
    "            print(msg.format(i + 1, a))\n",
    "            \n",
    "        tot_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def acc_test():\n",
    "    a = session.run(acc, feed_dict={\n",
    "        x: data.test.images,\n",
    "        y_: data.test.labels,\n",
    "        keep_prob: 1.0\n",
    "    })\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    101, Acc:  55.8%\n",
      "Iteration:    201, Acc:  74.9%\n",
      "Iteration:    301, Acc:  83.2%\n",
      "Iteration:    401, Acc:  85.2%\n",
      "Iteration:    501, Acc:  89.2%\n",
      "Iteration:    601, Acc:  90.2%\n",
      "Iteration:    701, Acc:  92.0%\n",
      "Iteration:    801, Acc:  94.1%\n",
      "Iteration:    901, Acc:  91.6%\n",
      "Iteration:   1001, Acc:  93.8%\n"
     ]
    }
   ],
   "source": [
    "optimize(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9634\n"
     ]
    }
   ],
   "source": [
    "acc_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After about 1k iterations, out train acc is at 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
